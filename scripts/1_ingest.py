from langchain.document_loaders import PyPDFLoader  # or any loader you're using
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# ğŸ“‚ Load document
loader = PyPDFLoader("../data/sample.pdf")  # Update path and loader type if needed
docs = loader.load()
print("âœ… Loaded document:", docs[0].metadata['source'])

# âœ‚ï¸ Split into chunks
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

# ğŸ§  Create embeddings
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectordb = FAISS.from_documents(chunks, embedding_model)

# ğŸ’¾ Save vectorstore
vectordb.save_local("../embeddings")
print("âœ… Ingestion complete. Embeddings saved to ../embeddings")
